{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqPGi7-dyFw0",
        "outputId": "4b41ec0f-1606-4565-a92e-fb798907295b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aspisov/asr.git\n",
        "!wget https://huggingface.co/aspisov/asr/resolve/main/model_best-193347.pth -O asr/model_best.pth\n",
        "!mkdir asr/saved\n",
        "!wget https://openslr.trmal.net/resources/11/librispeech-vocab.txt -O asr/saved/librispeech-vocab.txt\n",
        "!wget https://openslr.trmal.net/resources/11/3-gram.arpa.gz -O asr/saved/3-gram.arpa.gz\n",
        "!gunzip asr/saved/3-gram.arpa.gz\n",
        "!pip install --quiet gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHLS7tn4w0y1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "subprocess.run([\"uv\", \"sync\"], cwd=\"asr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccxtqes9ppe5",
        "outputId": "15d77754-b5f9-4b45-99a6-2d07b42c04fd"
      },
      "outputs": [],
      "source": [
        "# Fetch custom dataset from Google Drive\n",
        "GOOGLE_DRIVE_LINK = \"https://drive.google.com/drive/folders/1sqk3q9ejBDg76C8I15jXDLe87VQDZ2_f?usp=drive_link\"\n",
        "CUSTOM_ROOT = \"data/custom_drive\"\n",
        "BATCH_SIZE = 5\n",
        "!gdown --folder {GOOGLE_DRIVE_LINK} -O asr/{CUSTOM_ROOT}\n",
        "\n",
        "\n",
        "def run_inference(name: str, config: str, checkpoint: str, extra_args=None):\n",
        "    env = os.environ.copy()\n",
        "    env[\"MPLBACKEND\"] = \"Agg\"\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"python3\", \"inference.py\",\n",
        "        f\"-cn={config}\", f\"inferencer.from_pretrained={checkpoint}\", f\"dataloader.batch_size={BATCH_SIZE}\",\n",
        "    ]\n",
        "    if extra_args:\n",
        "        cmd.extend(extra_args)\n",
        "    print(\" \".join(cmd))\n",
        "    result = subprocess.run(cmd, cwd=\"asr\", text=True, capture_output=True, env=env)\n",
        "    print(result.stdout)\n",
        "    print(result.stderr)\n",
        "\n",
        "CHECKPOINT_PATH = \"model_best.pth\"\n",
        "\n",
        "# Custom Drive dataset\n",
        "run_inference(\n",
        "    name=\"custom_drive\",\n",
        "    config=\"inference_custom.yaml\",\n",
        "    checkpoint=CHECKPOINT_PATH,\n",
        "    extra_args=[f\"custom_dataset.dataset_root={CUSTOM_ROOT}\"],\n",
        ")\n",
        "\n",
        "# LibriSpeech test-clean\n",
        "run_inference(\n",
        "    name=\"test_clean\",\n",
        "    config=\"inference_test_clean.yaml\",\n",
        "    checkpoint=CHECKPOINT_PATH,\n",
        ")\n",
        "\n",
        "# LibriSpeech test-other\n",
        "run_inference(\n",
        "    name=\"test_other\",\n",
        "    config=\"inference_test_other.yaml\",\n",
        "    checkpoint=CHECKPOINT_PATH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obkHsfVhxQFq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
